{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "aOfHyMjZaFno",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "def generate_anchor(input_tensor, fmap_tensor):\n",
    "    # input shape \n",
    "    input_h = K.shape(inputs)[1]\n",
    "    input_w = K.shape(inputs)[2]\n",
    "\n",
    "    # backbone shape \n",
    "    backbone_h = K.shape(backbone_layer)[1]\n",
    "    backbone_w = K.shape(backbone_layer)[2]\n",
    "    \n",
    "    # to calculate the distance btw feature map pixels \n",
    "    pixel_gap = tf.ceil(input_h / backbone_h)\n",
    "    \n",
    "    # generate anchor sizes\n",
    "    anchor_default_sizes = [32., 64., 128.]  \n",
    "    anchor_ratio = [0.5, 1, 2]\n",
    "    n_anchor_sizes = len(anchor_default_sizes) * len(anchor_ratio)\n",
    "    anchor_sizes = [] \n",
    "    for size in anchor_default_sizes:\n",
    "        anchor_sizes.extend([[size, size],[size, size*2], [size*2, size]])\n",
    "    anchor_sizes = np.asarray(anchor_sizes)\n",
    "    \n",
    "    # generate anchor grid\n",
    "    # 4 => cx, cy, w, h\n",
    "    fmap_grid = tf.ones(shape=[backbone_h, backbone_w], dtype=tf.float64)\n",
    "\n",
    "    # generate coordinate center_x, center_y\n",
    "    range_h = tf.range(backbone_h)\n",
    "    range_w = tf.range(backbone_w)\n",
    "    cx, cy = tf.meshgrid(range_w, range_h)\n",
    "    cx = tf.cast(cx, tf.float64)\n",
    "    cy = tf.cast(cy, tf.float64)\n",
    "\n",
    "    # shift cx ,cy \n",
    "    # pixel_gap//2 은 stride 때문에 저렇게 된다. \n",
    "    # pixel 간 거리는 stride 만큼 떨어져 있다. \n",
    "    cx = cx * pixel_gap + pixel_gap//2\n",
    "\n",
    "    cy = cy * pixel_gap + pixel_gap//2\n",
    "\n",
    "    # cx 는 anchor 갯수만큼 있어서 저렇게 만든다 \n",
    "    grid_cx = tf.stack([cx]*n_anchor_sizes, axis=-1) \n",
    "    grid_cy = tf.stack([cy]*n_anchor_sizes, axis=-1) \n",
    "\n",
    "    # mapping ws, hs to anchor grid \n",
    "    anchor_ws = anchor_sizes[:, 0]\n",
    "    anchor_hs = anchor_sizes[:, 1]\n",
    "    grid_ws = tf.expand_dims(fmap_grid, axis=-1) * anchor_ws\n",
    "    grid_hs = tf.expand_dims(fmap_grid, axis=-1) * anchor_hs\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    Description:\n",
    "        grid_cx shape = (7,7,9), \n",
    "        grid_cx[0, 0, :] => [x1,x2,x3 .. ] \n",
    "        \n",
    "        grid_cy = shape = (7,7,9)                 [[x1, x2, x3, ...]\n",
    "        grid_cy[0, 0, :] => [y1,y2,y3 .. ]         [y1, y2, y3, ...]\n",
    "                                            ==>    [w1, w2, w3, ...]\n",
    "        grid_ws = shape = (7,7,9)                  [h1, h2, h3, ...]]\n",
    "        grid_ws[0, 0, :] => [w1,w2,w3 .. ] \n",
    "        \n",
    "        grid_hs = shape = (7,7,9)\n",
    "        grid_hs[0, 0, :] => [h1,h2,h3 .. ] \n",
    "    \"\"\" \n",
    "    anchor_grid = tf.stack([grid_cx, grid_cy, grid_ws, grid_hs], axis=-1)\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Description:\n",
    "    [[x1, x2, x3, ...]\n",
    "     [y1, y2, y3, ...]\n",
    "     [w1, w2, w3, ...]  => [x1,y1,w1,h1, x2,y2,w2,h2 ...] \n",
    "     [h1, h2, h3, ...]]\n",
    "\n",
    "    \"\"\" \n",
    "    anchor_grid = tf.reshape(anchor_grid, [backbone_h, backbone_w, -1])\n",
    "    return anchor_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VXSLFY-mazKx",
    "colab_type": "text"
   },
   "source": [
    "# Test Set up 코드 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "6RV0ZqGTaJyp",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import numpy as np \n",
    "from PIL import Image\n",
    "import tensorflow as tf \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from tensorflow.python.keras.applications import ResNet50\n",
    "from tensorflow.python.keras.layers import Layer\n",
    "from tensorflow.python.keras.layers import Conv2D\n",
    "from tensorflow.python.keras.layers import ZeroPadding2D\n",
    "from tensorflow.python.keras.layers import Input\n",
    "from tensorflow.python.keras.layers import UpSampling2D\n",
    "from tensorflow.python.keras.layers import BatchNormalization\n",
    "from tensorflow.python.keras.layers import Flatten\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "from tensorflow.python.keras.layers import Dropout\n",
    "from tensorflow.python.keras import optimizers\n",
    "from tensorflow.keras.models import Model\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "import urllib.request\n",
    "\n",
    "\n",
    "# Sample Image Download \n",
    "sample_name = '342.jpg'\n",
    "\n",
    "image_url = \"https://pai-datasets.s3.ap-northeast-2.amazonaws.com/pascal/images/{}\".format(sample_name)\n",
    "urllib.request.urlretrieve(image_url, \"sample_image.jpg\")\n",
    "\n",
    "mask_url = \"https://pai-datasets.s3.ap-northeast-2.amazonaws.com/pascal/roidb/{}.npy\".format(sample_name)\n",
    "urllib.request.urlretrieve(mask_url, \"sample_label.npy\")\n",
    "\n",
    "\n",
    "# Image Checking \n",
    "image_path = \"sample_image.jpg\"\n",
    "label_path = \"sample_label.npy\"\n",
    "\n",
    "\n",
    "# load sample image \n",
    "sample_img = np.asarray(Image.open(image_path).convert('RGB'))\n",
    "sample_img=sample_img/255.\n",
    "sample_tensor = np.expand_dims(sample_img, axis=0)\n",
    "\n",
    "# load label \n",
    "sample_bboxes = np.load(label_path).astype(np.int32)\n",
    "\n",
    "# draw bounding boxes \n",
    "for bbox in sample_bboxes:\n",
    "    print(bbox)\n",
    "    patched_image = sample_tensor[0].copy()\n",
    "    cv2.rectangle(patched_image, \n",
    "                                  (bbox[0], bbox[1]), \n",
    "                                  (bbox[2], bbox[3]),\n",
    "                                  (255,0,0),\n",
    "                                  10)\n",
    "plt.imshow(patched_image)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Sample CNN Model Setup \n",
    "inputs = Input(shape=(None, None, 3), name='images')\n",
    "backbone_layer = ResNet50(weights='imagenet', input_shape=(None,None,3), \n",
    "                 include_top=False)(inputs)\n",
    "\n",
    "# obejct detection layer \n",
    "n_anchor = 9 \n",
    "n_reg = 4 \n",
    "layer = Conv2D(filters = 128, activation='relu', kernel_size=3, padding='same')(backbone_layer)\n",
    "layer = Conv2D(filters = 256, activation='relu', kernel_size=3 ,padding='same')(layer)\n",
    "layer = Conv2D(filters = n_anchor * n_reg , activation='relu', kernel_size=3, padding='same')(layer)\n",
    "\n",
    "model = Model(inputs, layer)\n",
    "top_conv = model.predict(sample_tensor)\n",
    "\n",
    "\n",
    "def calculate_iou(sample_bboxes, gt_bboxes):\n",
    "    \n",
    "    \"\"\"\n",
    "    sample_bboxes : Ndarray, 1D array [x1, x2, y1, y2, x1, x2, y1, y2, ... ]\n",
    "    sample_bboxes : Ndarray, 1D array [x1, x2, y1, y2, x1, x2, y1, y2, ... ]\n",
    "    \"\"\"\n",
    "\n",
    "    # 1D array to 2D array \n",
    "    #[x1, x2, y1, y2, x1, x2, y1, y2 ]\n",
    "    # >>> \n",
    "    #[[x1, x2, y1, y2],\n",
    "    # [x1, x2, y1, y2]] \n",
    "    res_sample_bboxes = sample_bboxes.reshape([-1, 4])\n",
    "    gt_sample_bboxes = gt_bboxes.reshape([-1, 4])\n",
    "\n",
    "    # Get Area \n",
    "    area_sample = (res_sample_bboxes[:, 0] - res_sample_bboxes[:, 2]) * (res_sample_bboxes[:, 1] - res_sample_bboxes[:, 3])\n",
    "    area_gt = (gt_sample_bboxes[:, 0] - gt_sample_bboxes[:, 2]) * (gt_sample_bboxes[:, 1] - gt_sample_bboxes[:, 3])\n",
    "\n",
    "    # expand dims for using broadcasting\n",
    "    # (N, 4) -> (N, 1, 4)\n",
    "    expand_sample = np.expand_dims(res_sample_bboxes, axis=1)\n",
    "    # (N, 4) -> (1, N, 4)\n",
    "    expand_gt = np.expand_dims(gt_sample_bboxes, axis=0)\n",
    "\n",
    "    # search Maximun  \n",
    "    x1y1 = np.where(expand_sample[:, :, :2] > expand_gt[:, :, :2], expand_sample[:, :, :2], expand_gt[:, :, :2])\n",
    "    # search Minimun  \n",
    "    x2y2 = np.where(expand_sample[:, :, 2:] < expand_gt[:, :, 2:], expand_sample[:, :, 2:], expand_gt[:, :, 2:])\n",
    "\n",
    "    # get overlay area \n",
    "    overlay_area = np.prod(x1y1 - x2y2, axis=-1)\n",
    "    \n",
    "    # expand dimension for broadcasting \n",
    "    expand_area_sample= np.expand_dims(area_sample, axis=-1)\n",
    "\n",
    "    iou = overlay_area / (expand_area_sample + area_gt - overlay_area)\n",
    "\n",
    "    return iou\n",
    "\n",
    "def matching_policy(iou_matrix, iou_threshold=0.7):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        iou_matrix : Ndarray, 2D array \n",
    "        \n",
    "        [[anchor1_gt1 , anchor1_gt2,  anthor1_gt3],\n",
    "        [anchor2_gt1  , anchor2_gt2,  anthor2_gt3],\n",
    "        [anchor3_gt1  , anchor3_gt2,  anthor3_gt3],\n",
    "        [anchor4_gt1  , anchor4_gt2,  anthor4_gt3],\n",
    "        \n",
    "                        ...\n",
    "                        \n",
    "        [anchor5_gt1  , anchor5_gt2,  anthor5_gt3]]\n",
    "        \n",
    "        \n",
    "    Return:\n",
    "        anchor_flag : Ndarray, 1D array     \n",
    "    \"\"\"\n",
    "    threshold_mask = np.sum(iou_matrix > iou_threshold, axis=-1).astype(bool)\n",
    "    best_match_mask = np.argmax(iou_matrix, axis=0)\n",
    "    \n",
    "    \n",
    "    n_anchors = len(iou_matrix)\n",
    "    # -1 mean useless \n",
    "    anchor_flag = np.ones([n_anchors]) * -1 \n",
    "\n",
    "    # apply best & IOU > 70 anchors \n",
    "    anchor_flag[best_match_mask] = 1 \n",
    "    anchor_flag[threshold_mask] = 1 \n",
    "    assert len(anchor_flag) == len(iou_matrix)\n",
    "    return anchor_flag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qcTZyNdMbKaQ",
    "colab_type": "text"
   },
   "source": [
    "## Test Code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "CfjtjzUnavo8",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "anchor_grid = generate_anchor(inputs, backbone_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "Kk4jDwTobMWg",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "sess = K.get_session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "anchor_grid_ = sess.run(anchor_grid, {inputs:sample_tensor})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "6kOfTGTEbeHF",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "res_anchor_grid = anchor_grid_.reshape(anchor_grid_.shape[0],anchor_grid_.shape[1], 9, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "TuaNI1Ucbe1v",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# CX CY W H => X1 Y1 X2 Y2\n",
    "\n",
    "# x1\n",
    "x1_grid = res_anchor_grid[:,:,:,0] - res_anchor_grid[:,:,:,2]/2\n",
    "\n",
    "# x2\n",
    "x2_grid = res_anchor_grid[:,:,:,0] + res_anchor_grid[:,:,:,2]/2\n",
    "\n",
    "# y1\n",
    "y1_grid = res_anchor_grid[:,:,:,1] - res_anchor_grid[:,:,:,3]/2\n",
    "\n",
    "# y2\n",
    "y2_grid = res_anchor_grid[:,:,:,1] + res_anchor_grid[:,:,:,3]/2\n",
    "\n",
    "res_anchor_grid[:,:,:,0]=x1_grid\n",
    "res_anchor_grid[:,:,:,1]=y1_grid\n",
    "res_anchor_grid[:,:,:,2]=x2_grid\n",
    "res_anchor_grid[:,:,:,3]=y2_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "axdYsdD6bnZc",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "sample_anchor = res_anchor_grid.reshape(-1)\n",
    "ground_truth = sample_bboxes\n",
    "iou_matrix = calculate_iou(sample_anchor, ground_truth)\n",
    "matching_matrix = matching_policy(iou_matrix)\n",
    "matching_indices = np.where(matching_matrix == 1)\n",
    "\n",
    "repeat_matching_indices = np.repeat(matching_matrix, 4)\n",
    "pos_anchors = sample_anchor[np.where(repeat_matching_indices == 1)]\n",
    "pos_anchors = pos_anchors.reshape([-1, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "OwprNihqb6th",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "sample_bboxes\n",
    "print(pos_anchors.shape)\n",
    "for bbox in pos_anchors.astype(np.int32):\n",
    "    patched_image = sample_tensor[0].copy()\n",
    "\n",
    "    patched_image = cv2.rectangle(patched_image, \n",
    "                                  (bbox[0], bbox[1]), \n",
    "                                  (bbox[2], bbox[3]),\n",
    "                                  (255,0,0),\n",
    "                                  10)\n",
    "    plt.imshow(patched_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "3v_7z-FGcDbX",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "cvIQjii4cbPp",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "generate_anchors.ipynb",
   "provenance": [],
   "private_outputs": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}